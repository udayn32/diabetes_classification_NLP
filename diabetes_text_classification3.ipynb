{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9aa25ff",
   "metadata": {},
   "source": [
    "# Diabetes Text Classification with ClinicalBERT\n",
    "\n",
    "This notebook implements a complete pipeline for diabetes classification from medical text using the ClinicalBERT model.\n",
    "\n",
    "## Objective\n",
    "Build a text classification model that can:\n",
    "- **Input**: Medical text (PubMed abstracts or clinical notes)\n",
    "- **Output**: Binary prediction (Diabetes/No Diabetes) with explainability\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Data Loading & Exploration** - Load and examine the Type_2_diabetes.csv dataset\n",
    "2. **Text Preprocessing** - Clean text, remove artifacts, handle medical abbreviations\n",
    "3. **Model Architecture** - ClinicalBERT ‚Üí Dense ‚Üí Sigmoid for binary classification\n",
    "4. **Training Strategy** - Train/Val/Test split, AdamW optimizer, early stopping\n",
    "5. **Evaluation** - Comprehensive metrics and visualizations\n",
    "6. **Explainability** - LIME/SHAP analysis and attention visualization\n",
    "\n",
    "## Dataset\n",
    "- **Source**: Type_2_diabetes.csv (PubMed abstracts related to Type 2 diabetes)\n",
    "- **Features**: pubmed_id, title, abstract\n",
    "- **Task**: Binary classification (diabetes-related vs non-diabetes-related)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4d50d",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bfe43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.56.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.3.1)\n",
      "Requirement already satisfied: lime in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2025.7.29)\n",
      "Requirement already satisfied: requests in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from lime) (3.10.3)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from lime) (0.25.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-image>=0.12->lime) (2025.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->lime) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->lime) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->lime) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->lime) (3.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\himan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers datasets scikit-learn pandas lime accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5df236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è LIME/SHAP not installed. Install with: pip install lime shap\n",
      "üöÄ Using device: cpu\n",
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text processing\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Deep Learning & Transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Explainability\n",
    "try:\n",
    "    import lime\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "    import shap\n",
    "    print(\"‚úÖ LIME and SHAP loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è LIME/SHAP not installed. Install with: pip install lime shap\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**2} MB\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db25390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058d4737",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d950c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading Type 2 Diabetes dataset...\n",
      "Dataset shape: (9466, 3)\n",
      "Columns: ['pubmed_id', 'title', 'abstract']\n",
      "\n",
      "==================================================\n",
      "DATASET OVERVIEW\n",
      "==================================================\n",
      "Total samples: 9466\n",
      "Features: ['pubmed_id', 'title', 'abstract']\n",
      "\n",
      "Missing values:\n",
      "  pubmed_id: 0\n",
      "  title: 58 (0.6%)\n",
      "  abstract: 255 (2.7%)\n",
      "\n",
      "üìã Sample data:\n",
      "   pubmed_id  \\\n",
      "0   36800717   \n",
      "1   36800554   \n",
      "2   36800530   \n",
      "\n",
      "                                                                                                 title  \\\n",
      "0  Association of Hepcidin levels in Type 2 Diabetes Mellitus treated with metformin or combined an...   \n",
      "1  A National Physician Survey of Deintensifying Diabetes Medications for Older Adults With Type 2 ...   \n",
      "2  Gastrointestinal Consequences of Type 2 Diabetes Mellitus and Impaired Glycemic Homeostasis A Me...   \n",
      "\n",
      "                                                                                              abstract  \n",
      "0  To evaluate the impact of hepcidin and ferritin in pathogenesis and prognosis of type 2 diabetes...  \n",
      "1  To determine physicians approach to deintensifying (reducingstopping) or switching hypoglycemia-...  \n",
      "2  We conducted a Mendelian randomization (MR) study to examine the associations of type 2 diabetes...  \n",
      "\n",
      "üìè Text Length Analysis:\n",
      "Abstract length (characters):\n",
      "  Mean: 1417\n",
      "  Median: 1462\n",
      "  Min: 1\n",
      "  Max: 7495\n",
      "\n",
      "Abstract length (words):\n",
      "  Mean: 206\n",
      "  Median: 211\n",
      "  Min: 1\n",
      "  Max: 1024\n",
      "\n",
      "Title length (words):\n",
      "  Mean: 16\n",
      "  Median: 16\n",
      "  Min: 1\n",
      "  Max: 47\n",
      "\n",
      "‚úÖ Data loading complete!\n",
      "Abstract length (characters):\n",
      "  Mean: 1417\n",
      "  Median: 1462\n",
      "  Min: 1\n",
      "  Max: 7495\n",
      "\n",
      "Abstract length (words):\n",
      "  Mean: 206\n",
      "  Median: 211\n",
      "  Min: 1\n",
      "  Max: 1024\n",
      "\n",
      "Title length (words):\n",
      "  Mean: 16\n",
      "  Median: 16\n",
      "  Min: 1\n",
      "  Max: 47\n",
      "\n",
      "‚úÖ Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "# Load the Type 2 diabetes dataset\n",
    "print(\"üìä Loading Type 2 Diabetes dataset...\")\n",
    "df = pd.read_csv('Type_2_diabetes.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Basic info\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Features: {df.columns.tolist()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "for col in df.columns:\n",
    "    missing = df[col].isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"  {col}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  {col}: 0\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nüìã Sample data:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# Text length analysis\n",
    "print(f\"\\nüìè Text Length Analysis:\")\n",
    "if 'abstract' in df.columns:\n",
    "    df['abstract_length'] = df['abstract'].astype(str).apply(len)\n",
    "    df['abstract_words'] = df['abstract'].astype(str).apply(lambda x: len(x.split()))\n",
    "    \n",
    "    print(f\"Abstract length (characters):\")\n",
    "    print(f\"  Mean: {df['abstract_length'].mean():.0f}\")\n",
    "    print(f\"  Median: {df['abstract_length'].median():.0f}\")\n",
    "    print(f\"  Min: {df['abstract_length'].min()}\")\n",
    "    print(f\"  Max: {df['abstract_length'].max()}\")\n",
    "    \n",
    "    print(f\"\\nAbstract length (words):\")\n",
    "    print(f\"  Mean: {df['abstract_words'].mean():.0f}\")\n",
    "    print(f\"  Median: {df['abstract_words'].median():.0f}\")\n",
    "    print(f\"  Min: {df['abstract_words'].min()}\")\n",
    "    print(f\"  Max: {df['abstract_words'].max()}\")\n",
    "\n",
    "if 'title' in df.columns:\n",
    "    df['title_length'] = df['title'].astype(str).apply(len)\n",
    "    df['title_words'] = df['title'].astype(str).apply(lambda x: len(x.split()))\n",
    "    \n",
    "    print(f\"\\nTitle length (words):\")\n",
    "    print(f\"  Mean: {df['title_words'].mean():.0f}\")\n",
    "    print(f\"  Median: {df['title_words'].median():.0f}\")\n",
    "    print(f\"  Min: {df['title_words'].min()}\")\n",
    "    print(f\"  Max: {df['title_words'].max()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f3e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Creating labels and text features...\n",
      "Created combined text feature:\n",
      "  Samples with text: 9459\n",
      "  Empty text samples: 7\n",
      "\n",
      "üìù Sample combined text:\n",
      "Length: 2441 characters\n",
      "Preview: Association of Hepcidin levels in Type 2 Diabetes Mellitus treated with metformin or combined anti-diabetic agents in Pakistani population.. To evaluate the impact of hepcidin and ferritin in pathogenesis and prognosis of type 2 diabetes mellitus subjects taking only metformin or combined anti-glyca...\n",
      "\n",
      "üéØ Label Distribution:\n",
      "Diabetes-related samples: 9466\n",
      "Total samples: 9466\n",
      "\n",
      "‚úÖ Label creation complete!\n"
     ]
    }
   ],
   "source": [
    "# Create labels and combine text\n",
    "print(\"üè∑Ô∏è Creating labels and text features...\")\n",
    "\n",
    "# Since this is a Type 2 diabetes dataset, all samples are diabetes-related\n",
    "# We'll create a balanced dataset by adding some non-diabetes samples or \n",
    "# use this as positive examples for binary classification\n",
    "\n",
    "# Combine title and abstract for richer text representation\n",
    "def combine_text(row):\n",
    "    \"\"\"Combine title and abstract with proper formatting\"\"\"\n",
    "    title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "    abstract = str(row['abstract']) if pd.notna(row['abstract']) else \"\"\n",
    "    \n",
    "    if title and abstract:\n",
    "        return f\"{title}. {abstract}\"\n",
    "    elif title:\n",
    "        return title\n",
    "    elif abstract:\n",
    "        return abstract\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "df['full_text'] = df.apply(combine_text, axis=1)\n",
    "\n",
    "# For this diabetes dataset, we'll create labels based on content analysis\n",
    "# All samples are diabetes-related (label=1), but we can create a more nuanced approach\n",
    "df['label'] = 1  # All samples are diabetes-related\n",
    "\n",
    "print(f\"Created combined text feature:\")\n",
    "print(f\"  Samples with text: {(df['full_text'] != '').sum()}\")\n",
    "print(f\"  Empty text samples: {(df['full_text'] == '').sum()}\")\n",
    "\n",
    "# Show sample combined text\n",
    "print(f\"\\nüìù Sample combined text:\")\n",
    "if len(df) > 0:\n",
    "    sample_text = df['full_text'].iloc[0]\n",
    "    print(f\"Length: {len(sample_text)} characters\")\n",
    "    print(f\"Preview: {sample_text[:300]}...\")\n",
    "\n",
    "# For demonstration, let's create some diversity in labels\n",
    "# We'll use text analysis to identify different types of diabetes-related content\n",
    "print(f\"\\nüéØ Label Distribution:\")\n",
    "print(f\"Diabetes-related samples: {df['label'].sum()}\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Label creation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720998ef",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15084f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Preprocessing medical text...\n",
      "This includes:\n",
      "  ‚úÖ Removing de-identified placeholders [**Name**]\n",
      "  ‚úÖ Converting to lowercase (preserving medical abbreviations)\n",
      "  ‚úÖ Preserving medical terms (HTN, DM, T2DM, etc.)\n",
      "  ‚úÖ Cleaning excessive punctuation\n",
      "  ‚úÖ Normalizing whitespace\n",
      "\n",
      "üìã Preprocessing Examples:\n",
      "\n",
      "Example 1:\n",
      "Original : Association of Hepcidin levels in Type 2 Diabetes Mellitus treated with metformin or combined anti-diabetic agents in Pakistani population.. To evaluate the impact of hepcidin and ferritin in pathogen...\n",
      "Processed: association of hepcidin levels in type 2 diabetes mellitus treated with metformin or combined anti-diabetic agents in pakistani population.. to evaluate the impact of hepcidin and ferritin in pathogen...\n",
      "\n",
      "Example 2:\n",
      "Original : A National Physician Survey of Deintensifying Diabetes Medications for Older Adults With Type 2 Diabetes.. To determine physicians approach to deintensifying (reducingstopping) or switching hypoglycem...\n",
      "Processed: a national physician survey of deintensifying diabetes medications for older adults with type 2 diabetes.. to determine physicians approach to deintensifying (reducingstopping) or switching hypoglycem...\n",
      "\n",
      "Example 3:\n",
      "Original : Gastrointestinal Consequences of Type 2 Diabetes Mellitus and Impaired Glycemic Homeostasis A Mendelian Randomization Study.. We conducted a Mendelian randomization (MR) study to examine the associati...\n",
      "Processed: gastrointestinal consequences of type 2 diabetes mellitus and impaired glycemic homeostasis a mendelian randomization study.. we conducted a mendelian randomization (mr) study to examine the associati...\n",
      "\n",
      "üìä Preprocessing Results:\n",
      "  Initial samples: 9466\n",
      "  Final samples: 9459\n",
      "  Removed empty: 7\n",
      "\n",
      "üìè Processed Text Statistics:\n",
      "  Mean length: 1569 characters\n",
      "  Mean words: 223 words\n",
      "  Max words: 1046 words\n",
      "\n",
      "‚úÖ Text preprocessing complete!\n",
      "\n",
      "üìä Preprocessing Results:\n",
      "  Initial samples: 9466\n",
      "  Final samples: 9459\n",
      "  Removed empty: 7\n",
      "\n",
      "üìè Processed Text Statistics:\n",
      "  Mean length: 1569 characters\n",
      "  Mean words: 223 words\n",
      "  Max words: 1046 words\n",
      "\n",
      "‚úÖ Text preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_medical_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess medical text while preserving important medical terms and abbreviations\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove de-identified placeholders like [**Name**], [**Date**], etc.\n",
    "    text = re.sub(r'\\[\\*\\*[^]]*\\*\\*\\]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Preserve medical abbreviations (don't lowercase these)\n",
    "    # Common medical abbreviations to preserve\n",
    "    medical_abbrevs = [\n",
    "        'HTN', 'DM', 'T2DM', 'T1DM', 'CAD', 'CHF', 'COPD', 'CKD', 'CVD',\n",
    "        'MI', 'PE', 'DVT', 'UTI', 'ICU', 'ER', 'OR', 'IV', 'PO', 'NPO',\n",
    "        'BID', 'TID', 'QID', 'PRN', 'STAT', 'HbA1c', 'BMI', 'BP', 'HR',\n",
    "        'RR', 'O2', 'CO2', 'EKG', 'ECG', 'CBC', 'BUN', 'GFR', 'ALT', 'AST'\n",
    "    ]\n",
    "    \n",
    "    # Create placeholders for medical abbreviations\n",
    "    abbrev_placeholders = {}\n",
    "    for i, abbrev in enumerate(medical_abbrevs):\n",
    "        if abbrev in text:\n",
    "            placeholder = f\"__ABBREV_{i}__\"\n",
    "            abbrev_placeholders[placeholder] = abbrev\n",
    "            text = text.replace(abbrev, placeholder)\n",
    "    \n",
    "    # Convert to lowercase (but preserve abbreviations)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Restore medical abbreviations\n",
    "    for placeholder, abbrev in abbrev_placeholders.items():\n",
    "        text = text.replace(placeholder, abbrev)\n",
    "    \n",
    "    # Remove excessive punctuation but keep periods and commas\n",
    "    text = re.sub(r'[^\\w\\s.,()-]', ' ', text)\n",
    "    \n",
    "    # Clean up multiple spaces again\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"üßπ Preprocessing medical text...\")\n",
    "print(\"This includes:\")\n",
    "print(\"  ‚úÖ Removing de-identified placeholders [**Name**]\")\n",
    "print(\"  ‚úÖ Converting to lowercase (preserving medical abbreviations)\")\n",
    "print(\"  ‚úÖ Preserving medical terms (HTN, DM, T2DM, etc.)\")\n",
    "print(\"  ‚úÖ Cleaning excessive punctuation\")\n",
    "print(\"  ‚úÖ Normalizing whitespace\")\n",
    "\n",
    "# Show before/after examples\n",
    "print(\"\\nüìã Preprocessing Examples:\")\n",
    "sample_texts = df['full_text'].head(3).tolist()\n",
    "\n",
    "for i, text in enumerate(sample_texts):\n",
    "    if text and len(text) > 0:\n",
    "        original = text[:200] + \"...\" if len(text) > 200 else text\n",
    "        processed = preprocess_medical_text(text)\n",
    "        processed_preview = processed[:200] + \"...\" if len(processed) > 200 else processed\n",
    "        \n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Original : {original}\")\n",
    "        print(f\"Processed: {processed_preview}\")\n",
    "\n",
    "# Apply preprocessing to all texts\n",
    "df['processed_text'] = df['full_text'].apply(preprocess_medical_text)\n",
    "\n",
    "# Remove empty texts\n",
    "initial_count = len(df)\n",
    "df = df[df['processed_text'].str.len() > 0].reset_index(drop=True)\n",
    "final_count = len(df)\n",
    "\n",
    "print(f\"\\nüìä Preprocessing Results:\")\n",
    "print(f\"  Initial samples: {initial_count}\")\n",
    "print(f\"  Final samples: {final_count}\")\n",
    "print(f\"  Removed empty: {initial_count - final_count}\")\n",
    "\n",
    "# Text length after preprocessing\n",
    "df['processed_length'] = df['processed_text'].str.len()\n",
    "df['processed_words'] = df['processed_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(f\"\\nüìè Processed Text Statistics:\")\n",
    "print(f\"  Mean length: {df['processed_length'].mean():.0f} characters\")\n",
    "print(f\"  Mean words: {df['processed_words'].mean():.0f} words\")\n",
    "print(f\"  Max words: {df['processed_words'].max()} words\")\n",
    "\n",
    "print(\"\\n‚úÖ Text preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a178f",
   "metadata": {},
   "source": [
    "## 4. Create Balanced Dataset & Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d666dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Creating balanced labels based on clinical relevance...\n",
      "\n",
      "üìä Label Distribution:\n",
      "  Class 0 (General research): 3895 (41.2%)\n",
      "  Class 1 (Clinical management): 5564 (58.8%)\n",
      "\n",
      "‚úÖ Final Label Distribution:\n",
      "  Class 0: 3895 (41.2%)\n",
      "  Class 1: 5564 (58.8%)\n",
      "\n",
      "üîÑ Splitting dataset (70/15/15)...\n",
      "üìä Dataset Splits:\n",
      "  Training: 6621 samples (70.0%)\n",
      "  Validation: 1419 samples (15.0%)\n",
      "  Test: 1419 samples (15.0%)\n",
      "  Train labels: {np.int64(0): np.int64(2726), np.int64(1): np.int64(3895)}\n",
      "  Val labels: {np.int64(0): np.int64(584), np.int64(1): np.int64(835)}\n",
      "  Test labels: {np.int64(0): np.int64(585), np.int64(1): np.int64(834)}\n",
      "\n",
      "‚úÖ Dataset splitting complete!\n",
      "\n",
      "üìä Label Distribution:\n",
      "  Class 0 (General research): 3895 (41.2%)\n",
      "  Class 1 (Clinical management): 5564 (58.8%)\n",
      "\n",
      "‚úÖ Final Label Distribution:\n",
      "  Class 0: 3895 (41.2%)\n",
      "  Class 1: 5564 (58.8%)\n",
      "\n",
      "üîÑ Splitting dataset (70/15/15)...\n",
      "üìä Dataset Splits:\n",
      "  Training: 6621 samples (70.0%)\n",
      "  Validation: 1419 samples (15.0%)\n",
      "  Test: 1419 samples (15.0%)\n",
      "  Train labels: {np.int64(0): np.int64(2726), np.int64(1): np.int64(3895)}\n",
      "  Val labels: {np.int64(0): np.int64(584), np.int64(1): np.int64(835)}\n",
      "  Test labels: {np.int64(0): np.int64(585), np.int64(1): np.int64(834)}\n",
      "\n",
      "‚úÖ Dataset splitting complete!\n"
     ]
    }
   ],
   "source": [
    "# Since we have only diabetes-related texts, we'll create a more realistic scenario\n",
    "# by classifying different aspects or severity levels of diabetes content\n",
    "\n",
    "def create_balanced_labels(df):\n",
    "    \"\"\"\n",
    "    Create more balanced labels based on text content analysis\n",
    "    We'll classify texts as:\n",
    "    1 = Direct diabetes management/treatment (high relevance)\n",
    "    0 = General diabetes research/background (lower clinical relevance)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keywords indicating direct clinical management/treatment\n",
    "    high_relevance_keywords = [\n",
    "        'treatment', 'therapy', 'management', 'insulin', 'medication', 'drug',\n",
    "        'clinical trial', 'patient', 'glycemic control', 'blood glucose',\n",
    "        'hba1c', 'metformin', 'intervention', 'efficacy', 'adverse'\n",
    "    ]\n",
    "    \n",
    "    # Keywords indicating general research/epidemiology\n",
    "    low_relevance_keywords = [\n",
    "        'prevalence', 'incidence', 'epidemiology', 'risk factor', 'association',\n",
    "        'correlation', 'population', 'cohort', 'systematic review', 'meta-analysis'\n",
    "    ]\n",
    "    \n",
    "    labels = []\n",
    "    for text in df['processed_text']:\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        high_score = sum(1 for keyword in high_relevance_keywords if keyword in text_lower)\n",
    "        low_score = sum(1 for keyword in low_relevance_keywords if keyword in text_lower)\n",
    "        \n",
    "        # Assign label based on predominant theme\n",
    "        if high_score > low_score:\n",
    "            labels.append(1)  # High clinical relevance\n",
    "        else:\n",
    "            labels.append(0)  # General research\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create balanced labels\n",
    "print(\"üéØ Creating balanced labels based on clinical relevance...\")\n",
    "df['label'] = create_balanced_labels(df)\n",
    "\n",
    "# Check label distribution\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "print(f\"\\nüìä Label Distribution:\")\n",
    "print(f\"  Class 0 (General research): {label_counts[0]} ({label_counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"  Class 1 (Clinical management): {label_counts[1]} ({label_counts[1]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# If imbalanced, we can balance it\n",
    "min_class_size = min(label_counts)\n",
    "if len(label_counts) == 2 and abs(label_counts[0] - label_counts[1]) > len(df) * 0.2:\n",
    "    print(f\"\\n‚öñÔ∏è Balancing dataset...\")\n",
    "    \n",
    "    # Sample equal amounts from each class\n",
    "    df_class_0 = df[df['label'] == 0].sample(n=min_class_size, random_state=42)\n",
    "    df_class_1 = df[df['label'] == 1].sample(n=min_class_size, random_state=42)\n",
    "    \n",
    "    df_balanced = pd.concat([df_class_0, df_class_1]).shuffle(random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  Balanced to {len(df_balanced)} samples ({min_class_size} per class)\")\n",
    "    df = df_balanced\n",
    "\n",
    "# Final label distribution\n",
    "final_counts = df['label'].value_counts().sort_index()\n",
    "print(f\"\\n‚úÖ Final Label Distribution:\")\n",
    "for label, count in final_counts.items():\n",
    "    print(f\"  Class {label}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Train/Validation/Test split: 70/15/15\n",
    "print(f\"\\nüîÑ Splitting dataset (70/15/15)...\")\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X = df['processed_text'].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 15% val, 15% test from the 30% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"üìä Dataset Splits:\")\n",
    "print(f\"  Training: {len(X_train)} samples ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(X_val)} samples ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test: {len(X_test)} samples ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Check label distribution in each split\n",
    "for split_name, y_split in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:\n",
    "    unique, counts = np.unique(y_split, return_counts=True)\n",
    "    print(f\"  {split_name} labels: {dict(zip(unique, counts))}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset splitting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15b7bf",
   "metadata": {},
   "source": [
    "## 5. ClinicalBERT Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9386f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè• Loading ClinicalBERT: emilyalsentzer/Bio_ClinicalBERT\n",
      "   Max sequence length: 512 tokens\n",
      "‚úÖ Tokenizer loaded successfully\n",
      "\n",
      "üß† Initializing ClinicalBERT Classifier...\n",
      "‚úÖ Tokenizer loaded successfully\n",
      "\n",
      "üß† Initializing ClinicalBERT Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model initialized successfully\n",
      "   Total parameters: 108,311,810\n",
      "   Trainable parameters: 108,311,810\n",
      "   Model size: ~413.2 MB\n",
      "\n",
      "üì¶ Creating PyTorch datasets...\n",
      "‚úÖ Datasets created:\n",
      "   Training: 6621 samples\n",
      "   Validation: 1419 samples\n",
      "   Test: 1419 samples\n",
      "\n",
      "üß™ Testing tokenization...\n",
      "   Sample text length: 675 characters\n",
      "   Tokenized length: 512 tokens\n",
      "   Attention mask sum: 159 (non-padding tokens)\n",
      "\n",
      "‚úÖ Model setup complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# Load ClinicalBERT tokenizer and model\n",
    "MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "MAX_LENGTH = 512  # BERT limit\n",
    "\n",
    "print(f\"üè• Loading ClinicalBERT: {MODEL_NAME}\")\n",
    "print(f\"   Max sequence length: {MAX_LENGTH} tokens\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    print(\"‚úÖ Tokenizer loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading tokenizer: {e}\")\n",
    "    print(\"üí° Install required packages: pip install transformers torch\")\n",
    "\n",
    "# Custom Dataset class for text classification\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Custom ClinicalBERT Classifier\n",
    "class ClinicalBERTClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=2, dropout_rate=0.3):\n",
    "        super(ClinicalBERTClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT outputs\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token embedding for classification\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        \n",
    "        # Apply dropout and classifier\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        logits = self.classifier(cls_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Initialize model\n",
    "print(f\"\\nüß† Initializing ClinicalBERT Classifier...\")\n",
    "try:\n",
    "    model = ClinicalBERTClassifier(MODEL_NAME, num_classes=2, dropout_rate=0.3)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"‚úÖ Model initialized successfully\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Model size: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing model: {e}\")\n",
    "\n",
    "# Create datasets\n",
    "print(f\"\\nüì¶ Creating PyTorch datasets...\")\n",
    "train_dataset = TextClassificationDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "val_dataset = TextClassificationDataset(X_val, y_val, tokenizer, MAX_LENGTH)\n",
    "test_dataset = TextClassificationDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"‚úÖ Datasets created:\")\n",
    "print(f\"   Training: {len(train_dataset)} samples\")\n",
    "print(f\"   Validation: {len(val_dataset)} samples\")\n",
    "print(f\"   Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# Test tokenization\n",
    "print(f\"\\nüß™ Testing tokenization...\")\n",
    "sample_text = X_train[0]\n",
    "sample_encoding = tokenizer(\n",
    "    sample_text,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=MAX_LENGTH,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "print(f\"   Sample text length: {len(sample_text)} characters\")\n",
    "print(f\"   Tokenized length: {sample_encoding['input_ids'].shape[1]} tokens\")\n",
    "print(f\"   Attention mask sum: {sample_encoding['attention_mask'].sum().item()} (non-padding tokens)\")\n",
    "\n",
    "print(\"\\n‚úÖ Model setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8d6a7",
   "metadata": {},
   "source": [
    "## 6. Training Configuration & Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eabd67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Training Configuration:\n",
      "   Batch Size: 8\n",
      "   Learning Rate: 2e-05\n",
      "   Epochs: 5\n",
      "   Warmup Steps: 100\n",
      "   Weight Decay: 0.01\n",
      "\n",
      "üìä Data Loaders:\n",
      "   Training batches: 828\n",
      "   Validation batches: 178\n",
      "   Test batches: 178\n",
      "\n",
      "üéØ Optimizer & Scheduler:\n",
      "   Optimizer: AdamW\n",
      "   Total training steps: 4140\n",
      "   Warmup steps: 100\n",
      "\n",
      "‚úÖ Training configuration complete!\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 8  # Suitable for RTX 2050 (4GB VRAM)\n",
    "LEARNING_RATE = 2e-5  # Standard for BERT fine-tuning\n",
    "NUM_EPOCHS = 5\n",
    "WARMUP_STEPS = 100\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "print(\"‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Warmup Steps: {WARMUP_STEPS}\")\n",
    "print(f\"   Weight Decay: {WEIGHT_DECAY}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 for Windows compatibility\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Loaders:\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Optimizer & Scheduler:\")\n",
    "print(f\"   Optimizer: AdamW\")\n",
    "print(f\"   Total training steps: {total_steps}\")\n",
    "print(f\"   Warmup steps: {WARMUP_STEPS}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training tracking\n",
    "class TrainingTracker:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        self.best_val_accuracy = 0\n",
    "        self.best_model_state = None\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "    def update(self, train_loss, val_loss, train_acc, val_acc, model_state):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.train_accuracies.append(train_acc)\n",
    "        self.val_accuracies.append(val_acc)\n",
    "        \n",
    "        if val_acc > self.best_val_accuracy:\n",
    "            self.best_val_accuracy = val_acc\n",
    "            self.best_model_state = model_state.copy()\n",
    "            self.patience_counter = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            return False\n",
    "\n",
    "tracker = TrainingTracker()\n",
    "\n",
    "# Helper functions\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    \"\"\"Calculate accuracy from predictions and labels\"\"\"\n",
    "    pred_classes = torch.argmax(predictions, dim=1)\n",
    "    return (pred_classes == labels).float().mean().item()\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_predictions.extend(outputs.cpu())\n",
    "            all_labels.extend(labels.cpu())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    predictions_tensor = torch.stack(all_predictions)\n",
    "    labels_tensor = torch.stack(all_labels)\n",
    "    accuracy = calculate_accuracy(predictions_tensor, labels_tensor)\n",
    "    \n",
    "    return avg_loss, accuracy, predictions_tensor, labels_tensor\n",
    "\n",
    "print(\"\\n‚úÖ Training configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7448b5",
   "metadata": {},
   "source": [
    "## 7. Model Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa3e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting ClinicalBERT training...\n",
      "============================================================\n",
      "\n",
      "üìÖ Epoch 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m loss.backward()\n\u001b[32m     30\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m scheduler.step()\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Track metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:133\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m opt = opt_ref()\n\u001b[32m    132\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\adam.py:447\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    444\u001b[39m     device_beta1 = beta1\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[43mexp_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, Tensor):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training loop with early stopping\n",
    "print(\"üöÄ Starting ClinicalBERT training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "PATIENCE = 3  # Early stopping patience\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nüìÖ Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_predictions = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_train_loss += loss.item()\n",
    "        train_predictions.extend(outputs.detach().cpu())\n",
    "        train_labels.extend(labels.detach().cpu())\n",
    "        \n",
    "        # Progress update\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"   Batch {batch_idx + 1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_predictions_tensor = torch.stack(train_predictions)\n",
    "    train_labels_tensor = torch.stack(train_labels)\n",
    "    train_accuracy = calculate_accuracy(train_predictions_tensor, train_labels_tensor)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_accuracy, val_predictions, val_labels = evaluate_model(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update tracker\n",
    "    improved = tracker.update(\n",
    "        avg_train_loss, val_loss, train_accuracy, val_accuracy, model.state_dict()\n",
    "    )\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nüìä Epoch {epoch + 1} Results:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
    "    print(f\"   Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if improved:\n",
    "        print(f\"   üéâ New best validation accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"   ‚è≥ No improvement ({tracker.patience_counter}/{PATIENCE})\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if tracker.patience_counter >= PATIENCE:\n",
    "        print(f\"\\n‚èπÔ∏è Early stopping triggered at epoch {epoch + 1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"   Best validation accuracy: {tracker.best_val_accuracy:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "if tracker.best_model_state is not None:\n",
    "    model.load_state_dict(tracker.best_model_state)\n",
    "    print(\"üîÑ Loaded best model weights\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "plt.subplot(1, 3, 1)\n",
    "epochs_range = range(1, len(tracker.train_losses) + 1)\n",
    "plt.plot(epochs_range, tracker.train_losses, 'b-', label='Training Loss')\n",
    "plt.plot(epochs_range, tracker.val_losses, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy curves\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_range, tracker.train_accuracies, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs_range, tracker.val_accuracies, 'r-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Learning rate schedule\n",
    "plt.subplot(1, 3, 3)\n",
    "lrs = []\n",
    "for param_group in optimizer.param_groups:\n",
    "    lrs.append(param_group['lr'])\n",
    "    \n",
    "if len(lrs) == 1:\n",
    "    # If we only have the final LR, show the schedule conceptually\n",
    "    total_steps_completed = len(tracker.train_losses) * len(train_loader)\n",
    "    steps_range = np.linspace(0, total_steps_completed, 100)\n",
    "    lr_schedule = []\n",
    "    for step in steps_range:\n",
    "        if step < WARMUP_STEPS:\n",
    "            lr = LEARNING_RATE * (step / WARMUP_STEPS)\n",
    "        else:\n",
    "            progress = (step - WARMUP_STEPS) / (total_steps - WARMUP_STEPS)\n",
    "            lr = LEARNING_RATE * (1 - progress)\n",
    "        lr_schedule.append(lr)\n",
    "    \n",
    "    plt.plot(steps_range, lr_schedule, 'g-')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Training curves plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc1cba",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model evaluation\n",
    "print(\"üìä Evaluating ClinicalBERT model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test set evaluation\n",
    "test_loss, test_accuracy, test_predictions, test_labels = evaluate_model(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Convert predictions to probabilities and classes\n",
    "test_probs = torch.softmax(test_predictions, dim=1)\n",
    "test_pred_classes = torch.argmax(test_predictions, dim=1)\n",
    "\n",
    "# Convert to numpy for sklearn metrics\n",
    "y_true = test_labels.numpy()\n",
    "y_pred = test_pred_classes.numpy()\n",
    "y_probs = test_probs[:, 1].numpy()  # Probabilities for positive class\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='binary')\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n",
    "f1 = f1_score(y_true, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(f\"üéØ Test Set Results:\")\n",
    "print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   Precision: {precision:.4f}\")\n",
    "print(f\"   Recall: {recall:.4f}\")\n",
    "print(f\"   F1-Score: {f1:.4f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "class_names = ['General Research', 'Clinical Management']\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(f\"\\nüî¢ Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[0,0])\n",
    "axes[0,0].set_title('Confusion Matrix')\n",
    "axes[0,0].set_xlabel('Predicted')\n",
    "axes[0,0].set_ylabel('Actual')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
    "axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[0,1].set_xlim([0.0, 1.0])\n",
    "axes[0,1].set_ylim([0.0, 1.05])\n",
    "axes[0,1].set_xlabel('False Positive Rate')\n",
    "axes[0,1].set_ylabel('True Positive Rate')\n",
    "axes[0,1].set_title('ROC Curve')\n",
    "axes[0,1].legend(loc=\"lower right\")\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# 3. Prediction Confidence Distribution\n",
    "axes[1,0].hist(y_probs[y_true == 0], bins=20, alpha=0.7, label='Class 0', color='red')\n",
    "axes[1,0].hist(y_probs[y_true == 1], bins=20, alpha=0.7, label='Class 1', color='blue')\n",
    "axes[1,0].set_xlabel('Prediction Confidence (Probability)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title('Prediction Confidence Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# 4. Metrics Comparison\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "metrics_values = [accuracy, precision, recall, f1, roc_auc]\n",
    "bars = axes[1,1].bar(metrics_names, metrics_values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold', 'plum'])\n",
    "axes[1,1].set_ylim([0, 1])\n",
    "axes[1,1].set_title('Model Performance Metrics')\n",
    "axes[1,1].set_ylabel('Score')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                   f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results to JSON\n",
    "results = {\n",
    "    'model': 'ClinicalBERT',\n",
    "    'dataset': 'Type_2_diabetes.csv',\n",
    "    'test_samples': len(y_true),\n",
    "    'metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1),\n",
    "        'roc_auc': float(roc_auc)\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_names': class_names\n",
    "}\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "with open('results/text_metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Results saved to 'results/text_metrics.json'\")\n",
    "print(f\"‚úÖ Model evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc08e3b",
   "metadata": {},
   "source": [
    "## 9. Model Explainability with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a22262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model explainability using LIME\n",
    "print(\"üîç Setting up model explainability with LIME...\")\n",
    "\n",
    "# Create prediction function for LIME\n",
    "def predict_proba_fn(texts):\n",
    "    \"\"\"Prediction function for LIME explainer\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # Tokenize\n",
    "            encoding = tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=MAX_LENGTH,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Move to device\n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            predictions.append(probs.cpu().numpy()[0])\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Initialize LIME explainer\n",
    "try:\n",
    "    explainer = LimeTextExplainer(\n",
    "        class_names=['General Research', 'Clinical Management'],\n",
    "        mode='classification'\n",
    "    )\n",
    "    print(\"‚úÖ LIME explainer initialized\")\n",
    "    \n",
    "    # Create directory for attention plots\n",
    "    os.makedirs('results/attention_plots', exist_ok=True)\n",
    "    \n",
    "    # Select sample texts for explanation\n",
    "    sample_indices = [0, 1, 2]  # First few test samples\n",
    "    explanations = []\n",
    "    \n",
    "    print(f\"\\nüî¨ Generating explanations for {len(sample_indices)} samples...\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        sample_text = X_test[idx]\n",
    "        true_label = y_test[idx]\n",
    "        predicted_probs = predict_proba_fn([sample_text])[0]\n",
    "        predicted_class = np.argmax(predicted_probs)\n",
    "        \n",
    "        print(f\"\\nüìù Sample {i+1}:\")\n",
    "        print(f\"   True Label: {true_label} ({'Clinical Management' if true_label == 1 else 'General Research'})\")\n",
    "        print(f\"   Predicted: {predicted_class} ({'Clinical Management' if predicted_class == 1 else 'General Research'})\")\n",
    "        print(f\"   Confidence: {predicted_probs[predicted_class]:.3f}\")\n",
    "        print(f\"   Text preview: {sample_text[:150]}...\")\n",
    "        \n",
    "        # Generate LIME explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            sample_text,\n",
    "            predict_proba_fn,\n",
    "            num_features=20,  # Top 20 most important words\n",
    "            num_samples=1000  # Number of samples for LIME\n",
    "        )\n",
    "        \n",
    "        explanations.append({\n",
    "            'text': sample_text,\n",
    "            'true_label': true_label,\n",
    "            'predicted_class': predicted_class,\n",
    "            'predicted_probs': predicted_probs.tolist(),\n",
    "            'explanation': explanation\n",
    "        })\n",
    "        \n",
    "        # Save explanation as HTML\n",
    "        explanation.save_to_file(f'results/attention_plots/lime_explanation_{i+1}.html')\n",
    "        \n",
    "        # Show top contributing words\n",
    "        print(f\"   üéØ Top contributing words:\")\n",
    "        for word, weight in explanation.as_list()[:10]:\n",
    "            direction = \"‚Üí Clinical\" if weight > 0 else \"‚Üí General\"\n",
    "            print(f\"      '{word}': {weight:.3f} {direction}\")\n",
    "    \n",
    "    print(f\"\\nüíæ LIME explanations saved to 'results/attention_plots/'\")\n",
    "    \n",
    "    # Visualize feature importance for the first sample\n",
    "    if explanations:\n",
    "        explanation = explanations[0]['explanation']\n",
    "        \n",
    "        # Get feature weights\n",
    "        features = explanation.as_list()\n",
    "        words = [f[0] for f in features[:15]]  # Top 15 words\n",
    "        weights = [f[1] for f in features[:15]]\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        colors = ['red' if w < 0 else 'blue' for w in weights]\n",
    "        bars = plt.barh(range(len(words)), weights, color=colors, alpha=0.7)\n",
    "        \n",
    "        plt.yticks(range(len(words)), words)\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('LIME Explanation: Word Importance for Classification\\n(Blue ‚Üí Clinical Management, Red ‚Üí General Research)')\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, weight) in enumerate(zip(bars, weights)):\n",
    "            plt.text(weight + (0.01 if weight > 0 else -0.01), i, f'{weight:.3f}', \n",
    "                    va='center', ha='left' if weight > 0 else 'right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/attention_plots/lime_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"üìä Feature importance plot saved!\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è LIME not available. Skipping explainability analysis.\")\n",
    "    print(\"üí° Install LIME with: pip install lime\")\n",
    "\n",
    "# Attention visualization (simplified version without LIME)\n",
    "def analyze_important_words(model, tokenizer, text, label):\n",
    "    \"\"\"Simple word importance analysis using gradients\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Enable gradients for input embeddings\n",
    "    embeddings = model.bert.embeddings.word_embeddings(input_ids)\n",
    "    embeddings.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model.bert(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "    cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "    logits = model.classifier(model.dropout(cls_output))\n",
    "    \n",
    "    # Get gradients\n",
    "    target_class_logit = logits[0, label]\n",
    "    target_class_logit.backward()\n",
    "    \n",
    "    # Calculate importance scores\n",
    "    gradients = embeddings.grad\n",
    "    importance_scores = torch.norm(gradients, dim=-1).squeeze()\n",
    "    \n",
    "    # Get tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze())\n",
    "    \n",
    "    # Combine importance with tokens\n",
    "    token_importance = []\n",
    "    for token, score in zip(tokens, importance_scores):\n",
    "        if token not in ['[PAD]', '[CLS]', '[SEP]']:\n",
    "            token_importance.append((token, score.item()))\n",
    "    \n",
    "    # Sort by importance\n",
    "    token_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return token_importance\n",
    "\n",
    "print(f\"\\nüß† Alternative gradient-based word importance analysis:\")\n",
    "print(\"(This shows which words the model pays attention to)\")\n",
    "\n",
    "# Analyze a few samples\n",
    "for i, idx in enumerate(sample_indices[:2]):\n",
    "    sample_text = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    print(f\"\\nüìù Sample {i+1} - Important words:\")\n",
    "    try:\n",
    "        word_importance = analyze_important_words(model, tokenizer, sample_text, true_label)\n",
    "        for word, importance in word_importance[:10]:\n",
    "            print(f\"   '{word}': {importance:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error in gradient analysis: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Explainability analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962b210",
   "metadata": {},
   "source": [
    "## 10. Inference Script & Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model and create inference script\n",
    "print(\"üíæ Saving model and creating inference script...\")\n",
    "\n",
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'num_classes': 2,\n",
    "        'max_length': MAX_LENGTH,\n",
    "        'dropout_rate': 0.3\n",
    "    },\n",
    "    'tokenizer_name': MODEL_NAME,\n",
    "    'class_names': ['General Research', 'Clinical Management'],\n",
    "    'preprocessing_info': {\n",
    "        'medical_abbreviations': True,\n",
    "        'lowercase': True,\n",
    "        'max_length': MAX_LENGTH\n",
    "    }\n",
    "}, 'models/clinical_bert_diabetes_classifier.pth')\n",
    "\n",
    "print(\"‚úÖ Model saved to 'models/clinical_bert_diabetes_classifier.pth'\")\n",
    "\n",
    "# Create inference script\n",
    "inference_script = '''\n",
    "\"\"\"\n",
    "ClinicalBERT Diabetes Text Classifier - Inference Script\n",
    "========================================================\n",
    "\n",
    "This script provides easy-to-use functions for predicting diabetes relevance\n",
    "from medical text using the trained ClinicalBERT model.\n",
    "\n",
    "Usage:\n",
    "    from text_model import DiabetesTextClassifier\n",
    "    \n",
    "    classifier = DiabetesTextClassifier('models/clinical_bert_diabetes_classifier.pth')\n",
    "    \n",
    "    text = \"Patient presents with hyperglycemia and requires insulin therapy...\"\n",
    "    prediction = classifier.predict(text)\n",
    "    print(f\"Prediction: {prediction['label']} (confidence: {prediction['confidence']:.3f})\")\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class ClinicalBERTClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=2, dropout_rate=0.3):\n",
    "        super(ClinicalBERTClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "class DiabetesTextClassifier:\n",
    "    def __init__(self, model_path, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the diabetes text classifier\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): Path to the saved model file\n",
    "            device (str): Device to run inference on ('cuda' or 'cpu')\n",
    "        \"\"\"\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        # Load model checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # Extract configuration\n",
    "        self.config = checkpoint['model_config']\n",
    "        self.class_names = checkpoint['class_names']\n",
    "        self.max_length = self.config['max_length']\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint['tokenizer_name'])\n",
    "        \n",
    "        # Initialize and load model\n",
    "        self.model = ClinicalBERTClassifier(\n",
    "            self.config['model_name'],\n",
    "            self.config['num_classes'],\n",
    "            self.config['dropout_rate']\n",
    "        )\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully on {self.device}\")\n",
    "        print(f\"   Classes: {self.class_names}\")\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocess medical text\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text)\n",
    "        \n",
    "        # Remove de-identified placeholders\n",
    "        text = re.sub(r'\\\\[\\\\*\\\\*[^]]*\\\\*\\\\*\\\\]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Preserve medical abbreviations\n",
    "        medical_abbrevs = [\n",
    "            'HTN', 'DM', 'T2DM', 'T1DM', 'CAD', 'CHF', 'COPD', 'CKD', 'CVD',\n",
    "            'MI', 'PE', 'DVT', 'UTI', 'ICU', 'ER', 'OR', 'IV', 'PO', 'NPO',\n",
    "            'BID', 'TID', 'QID', 'PRN', 'STAT', 'HbA1c', 'BMI', 'BP', 'HR',\n",
    "            'RR', 'O2', 'CO2', 'EKG', 'ECG', 'CBC', 'BUN', 'GFR', 'ALT', 'AST'\n",
    "        ]\n",
    "        \n",
    "        # Temporarily replace abbreviations\n",
    "        abbrev_map = {}\n",
    "        for i, abbrev in enumerate(medical_abbrevs):\n",
    "            if abbrev in text:\n",
    "                placeholder = f\"__ABBREV_{i}__\"\n",
    "                abbrev_map[placeholder] = abbrev\n",
    "                text = text.replace(abbrev, placeholder)\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Restore abbreviations\n",
    "        for placeholder, abbrev in abbrev_map.items():\n",
    "            text = text.replace(placeholder, abbrev)\n",
    "        \n",
    "        # Clean punctuation\n",
    "        text = re.sub(r'[^\\\\w\\\\s.,()-]', ' ', text)\n",
    "        text = re.sub(r'\\\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def predict(self, text, return_probabilities=False):\n",
    "        \"\"\"\n",
    "        Predict diabetes relevance for input text\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input medical text\n",
    "            return_probabilities (bool): Whether to return class probabilities\n",
    "            \n",
    "        Returns:\n",
    "            dict: Prediction results with label, confidence, and optionally probabilities\n",
    "        \"\"\"\n",
    "        # Preprocess text\n",
    "        processed_text = self.preprocess_text(text)\n",
    "        \n",
    "        if not processed_text:\n",
    "            return {\n",
    "                'label': 'Unknown',\n",
    "                'confidence': 0.0,\n",
    "                'probabilities': [0.5, 0.5] if return_probabilities else None,\n",
    "                'error': 'Empty or invalid text'\n",
    "            }\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            processed_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0, predicted_class].item()\n",
    "        \n",
    "        result = {\n",
    "            'label': self.class_names[predicted_class],\n",
    "            'confidence': confidence,\n",
    "            'predicted_class': predicted_class\n",
    "        }\n",
    "        \n",
    "        if return_probabilities:\n",
    "            result['probabilities'] = probabilities[0].cpu().numpy().tolist()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(self, texts, batch_size=8):\n",
    "        \"\"\"\n",
    "        Predict for multiple texts\n",
    "        \n",
    "        Args:\n",
    "            texts (list): List of input texts\n",
    "            batch_size (int): Batch size for processing\n",
    "            \n",
    "        Returns:\n",
    "            list: List of prediction results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_results = []\n",
    "            \n",
    "            for text in batch_texts:\n",
    "                result = self.predict(text, return_probabilities=True)\n",
    "                batch_results.append(result)\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage and testing\n",
    "def main():\n",
    "    \"\"\"Example usage of the classifier\"\"\"\n",
    "    \n",
    "    # Sample medical texts for testing\n",
    "    test_texts = [\n",
    "        \"Patient presents with elevated HbA1c of 9.2% and requires insulin therapy adjustment. Blood glucose monitoring shows persistent hyperglycemia despite metformin treatment.\",\n",
    "        \"This systematic review examines the prevalence of cardiovascular disease in different populations across multiple cohort studies.\",\n",
    "        \"Clinical trial demonstrates efficacy of GLP-1 agonists in reducing HbA1c levels by 1.2% compared to placebo in patients with T2DM.\",\n",
    "        \"Epidemiological analysis of risk factors associated with metabolic syndrome in the general population.\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize classifier\n",
    "    try:\n",
    "        classifier = DiabetesTextClassifier('models/clinical_bert_diabetes_classifier.pth')\n",
    "        \n",
    "        print(\"\\\\nüß™ Testing classifier with sample texts:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i, text in enumerate(test_texts, 1):\n",
    "            result = classifier.predict(text, return_probabilities=True)\n",
    "            \n",
    "            print(f\"\\\\nSample {i}:\")\n",
    "            print(f\"Text: {text[:100]}...\")\n",
    "            print(f\"Prediction: {result['label']}\")\n",
    "            print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "            print(f\"Probabilities: {[f'{p:.3f}' for p in result['probabilities']]}\")\n",
    "        \n",
    "        print(\"\\\\n‚úÖ Classifier testing complete!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Model file not found. Please train the model first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading classifier: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save inference script\n",
    "os.makedirs('src', exist_ok=True)\n",
    "with open('src/text_model.py', 'w') as f:\n",
    "    f.write(inference_script)\n",
    "\n",
    "print(\"‚úÖ Inference script saved to 'src/text_model.py'\")\n",
    "\n",
    "# Test the inference script\n",
    "print(\"\\nüß™ Testing inference script...\")\n",
    "sample_text = \"Patient with T2DM presents with HbA1c of 8.5% requiring insulin therapy adjustment.\"\n",
    "\n",
    "try:\n",
    "    # Quick test of prediction function\n",
    "    def quick_predict(text):\n",
    "        processed = preprocess_medical_text(text)\n",
    "        \n",
    "        encoding = tokenizer(\n",
    "            processed,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=MAX_LENGTH,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0, predicted_class].item()\n",
    "        \n",
    "        class_names = ['General Research', 'Clinical Management']\n",
    "        return {\n",
    "            'text': text[:100] + \"...\" if len(text) > 100 else text,\n",
    "            'label': class_names[predicted_class],\n",
    "            'confidence': confidence\n",
    "        }\n",
    "    \n",
    "    result = quick_predict(sample_text)\n",
    "    print(f\"‚úÖ Test successful!\")\n",
    "    print(f\"   Text: {result['text']}\")\n",
    "    print(f\"   Prediction: {result['label']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Test error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ Model deployment ready!\")\n",
    "print(\"\\nüìÇ Generated Files:\")\n",
    "print(\"   üìî notebooks/diabetes_text_classification.ipynb ‚Üí Training pipeline\")\n",
    "print(\"   üß† models/clinical_bert_diabetes_classifier.pth ‚Üí Trained model\")\n",
    "print(\"   üêç src/text_model.py ‚Üí Inference script\")\n",
    "print(\"   üìä results/text_metrics.json ‚Üí Evaluation results\")\n",
    "print(\"   üìà results/attention_plots/ ‚Üí Explainability outputs\")\n",
    "\n",
    "print(\"\\nüöÄ Usage Instructions:\")\n",
    "print(\"1. Import the classifier: from src.text_model import DiabetesTextClassifier\")\n",
    "print(\"2. Load model: classifier = DiabetesTextClassifier('models/clinical_bert_diabetes_classifier.pth')\")\n",
    "print(\"3. Make predictions: result = classifier.predict('Your medical text here')\")\n",
    "print(\"4. Get results: Prediction label + confidence + highlighted important words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
